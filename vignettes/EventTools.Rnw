\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{fullpage}
%\usepackage[firstpage]{draftwatermark}
\title{EventTools: 2-piecewise Weibull and lagtimes}
\author{Daniel Dalevi}
% \VignetteIndexEntry{Predict from data - Basic tutorial}
%\VignetteEngine{knitr::knitr} 

%\SetWatermarkText{DRAFT: UNDER DEVELOPMENT}
%\SetWatermarkLightness{0.75}
%\SetWatermarkScale{2}

\begin{document}
\sloppy

<<include=FALSE>>=
library(knitr)
opts_chunk$set(
concordance=TRUE
)
@

\maketitle

\section{Introduction}
The eventTools package contains some extensions of functionality for the eventPrediction package. It will use the same interface when possible and the idea is to mimic the command-sequences used and propagate the functionality (accrual processes, dropouts etc). The first add-in is a method to allow for a change in the event rates at a specific time-point resulting from, for example, a lag-period. The data is aggregated during an ongoing trial and will be assumed blinded. This is related to the Predict from data functionality and is available in version $\ge 1.0$ of the eventTools package. The plan is to include more functionality to this package with iterative releases. 

\section{Preliminary steps}
Before starting this tutorial you will need to install the eventPrediction and the eventTools packages and their dependencies. For all examples below, ensure you load the libraries first. 
<<load,message=FALSE>>=
library( eventPrediction )
library( eventTools )
@

\section{Estimating the change-point}
\label{sec:changepoint}
The data used in this vignette is simulated under the assumption of a lag-time. The same approach can, however, be used for other situations where there is a change in the event rate during the trial resulting in data suitable for a 2-piecewise model (could also result from other types of non-proportional hazards). In the case of a lag-effect, the HR is $1$ until the change-point when treatment starts showing effect. The simulated OS data set is available in the package and we will be used for illustration. It contains $979$ subjects and assumes a lag-time of $165$ days and a post-lag HR of $0.25$. The control median was set to $5.8$ with a shape parameter of $1.2$. The study settings (not the simulated data) can be visualized using the \texttt{nonproportionalHazards} package (Figure~\ref{fig:nphz}, for details see the \texttt{nonproportionalHazards} documentation).
<<nphz, echo=FALSE, fig=TRUE, fig.cap="Visualizing the settings for the simulated data.">>=
library( nonproportionalHazards)
study <- delayedResponse( lag.time=5.5, 
                          median.control.time=5.8, 
                          hazard.ratio=0.25,
                          followup.time=20, 
                          total.patients=979, 
                          alpha=0.05,
                          randomization=1, 
                          accrual.duration=12, 
                          accrual.weight=1,
                          definition=hazard )
    landmark.times <- seq(0, 32, length.out=100)
    curves <- survival( study, landmark.times )
    plot( curves, xlab="Study time [months]" )
@
The dataset is loaded into R and an EventData object is created. The time is calculated from the event date and the last date. 
<<>>=
data( lag.data )

my.data <- EventData( data=lag.data,
                      subject="subject",
                      rand.date="randDate",
                      has.event="hasEvent",
                      withdrawn="withdrawn",
                      time=list( event.date="eventDate",
                                 last.date="lastDate" ) )
@
A model can be fitted to this (blinded) data (see EventPrediction vignette) without accounting for the lag-effect. The survival curve can be plotted with the model (Figure~\ref{fig:original}). 
<<original, fig.cap="Fitting the model using the eventPrediction package with a single Weibull survival function.">>=
my.fit <- fit( my.data )
plot( my.fit )
@

It is evident that the model fit is poor which is not surprising due to the nature of the data. Assuming that we have a change-point ($T$), there are various ways of estimating when this occurs. Perhaps the simplest is to include a co-variate (factor) in the survival method which is true if a subject is in the lag period and false otherwise. With an exponential survival function we can model the event rate as if constant before and after T. Given a set of possible change-points we can select the $T$ providing the best model fit. This may not always converge but in the package there is a function that visualize the fit given a search boundary for $T$ (Figure~\ref{fig:opt}). Note, the exponential survival function is set as default because it easily converges with a single parameter. Other distributions can also be selected. It is also important to note that currently no tests are made for the presence of a lag-effect. The method may give a change-point estimate though there is none and therefore it is also important to visually inspect the data (see also Section~\ref{sec:leftfit})   
<<opt, fig.cap="The optimal change-point based on an exponential model with a time covariate/indicator.">>=
  est.obj <- estimateLagTime( my.data, t.start=0.5, t.stop=20, dt=0.5 )
  plot( est.obj )
  estLagT <- getEstimate( est.obj )
@


\section{Right censor data based on the KM curve}
Different survival functions will be fitted before and after the estimated change-point dividing it into two parts. Since time in this case is subject specific, it will be relative to when subjects entered the study. The first part of the interval $[0,T)$ will be equivalent to a study with a fixed follow-up period of $T$ meaning that no subject is studied longer than $T$. We will refer to this data (and model) as \emph{KM right censored}. The package allows for cutting the data in this way using the function \texttt{KMRightCensor}. Then the normal \texttt{fit} function of the eventPrediction package will be used (Figure~\ref{fig:rightcens}).
 
<<rightcens, fig.cap="The model fitted on the right censored data.">>=
right.cens.data <- KMRightCensor( my.data, estLagT )
right.cens.fit <- fit( right.cens.data )
plot( right.cens.fit, ylim=c(0.5,1) )
@

The Weibull parameters can be obtained from the fitted object.
<<>>=
right.cens.fit@simParams@parameters
@

This can be compared to the original fit.
<<>>=
my.fit@simParams@parameters
@

\section{Fit a model on left truncated data}
\label{sec:leftfit}
The second part of the data will only contain subjects that survived longer than the change-point $[T,T_{analysis}]$ where $T_{analysis}$ is the time, relative to randomization, that we censored the subjects. This data (and model) will be referred to as \emph{left-truncated} as the subject has been at risk before entering the interval; it is conditioned that they have not had an event. The \texttt{LeftFit} function performs the necessary steps by first removing subjects with $t<T$ and then it fits the Weibull model. The estimation is done with the \texttt{weibreg} function from the \texttt{eha} package which is used internally, see vignette for more details and \cite{Brostrom:2012}.  

<<both, fig.cap="Including the model fitted on the left truncated and right censored data.">>=
 left.trunc.fit <- LeftFit( my.data, estLagT )
 left.trunc.fit@simParams@parameters
 plot( right.cens.fit, left.trunc.fit )
@

While the fit is much better than the original one, we can see that the tail may not be fully captured (Figure~\ref{fig:both}). Depending on the censoring status of the data and other aspects it may be hard to entirely automate the estimation of the change-point. Sometimes, for example, it may be more important to capture the tail of the distribution. Therefore it is important also to visually inspect the resulting curves. The implemented approach allows us to adjust the change-point and refit the models. In this case the tail may be better modelled by increasing it from $152$ to $160$ days (Figure~\ref{fig:bothmod}). In later versions (See Section~\ref{sec:futwork}) we aim to include an estimate of a CI for the change-point which would give an indication of the plausible value range.

<<bothmod, fig.cap="Including the model fitted on the left truncated and right censored data after moving the change-point.">>=
 estLagT <- 160 
 right.cens.data <- KMRightCensor( my.data, estLagT )
 right.cens.fit <- fit( right.cens.data )
 left.trunc.fit <- LeftFit( my.data, estLagT )
 plot( right.cens.fit, left.trunc.fit )
@

\section{Event Prediction}
We use an updated simulation procedure to incorporate the contribution from both models. For all patients, that have not had events and been in the trial for time $t$, we simulate events by: 
\begin{enumerate}
\item If $t<T$ draw an event time $t_{rc}$ from the right-censored model. 
\begin{enumerate}
	\item If $t_{rc}<T$ this will be recorded as the event time.
  \item	If $t_{rc} \ge T$, draw a new event time $t_{rc,lt}$ from the left-truncated model conditioned on $T$. $t_{rc,lt}$ will be the recorded event time.  
\end{enumerate}
\item If $t \ge T$ draw an event time $t_{lt}$ from the left-truncated model. This will be the event time. 
\end{enumerate}

This is iterated over a number of simulations (\texttt{Nsim}). The \texttt{simulatePW} function will accept the same arguments as \texttt{simulate} in the \texttt{eventPrediction} package. For example, adding new subjects (if still recruiting) can be achieved by adding the argument \texttt{accrualGenerator}. 

<<pred, fig.cap="Predictions using the piecewise model.">>=
  results <- simulatePW( right.cens.fit, left.trunc.fit,  
    Nsim = 500, #Number of simulations to perform
    seed = 20160322 ) #A random seed for reproducibility
  results <- predict( results, event.pred=900 )
  plot( results, show.title=TRUE) 
@

The expected time when reaching $900$ events for this data is $39$ months, i.e. April 2017 (Figure~\ref{fig:pred}). This can be compared with the prediction obtained from the original model (using a singel Weibull) which underestimates the data, April is outside the CI (Figure~\ref{fig:predorg}).

<<predorg, fig.cap="Predictions using the original implementation using a single Weibull.">>=
  results <- simulate( my.fit,  
    Nsim = 500, #Number of simulations to perform
    seed = 20160322 ) #A random seed for reproducibility
  results <- predict( results, event.pred=900 )
  plot( results, show.title=TRUE )
@


\section{N change-points}
The implementation allows for defining an arbitrary number of change-points; however, currently no method is available to get an estimate of more than one change-point (Section~\ref{sec:changepoint}). These need to be specified manually by inspecting the resulting KM curve. Here we use $4$ models separated by $3$ change-points for the same dataset (simulated under a 2-piecewise Weibull model).

<<npieces, fig.cap="Three change-points separating four Weibull models.">>=
  chP1 <- 50 
  chP2 <- 100 
  chP3 <- 160 
  
  # P1:
  right.cens.data.1 <- KMRightCensor( my.data, chP1 )
  fitP1 <- fit( right.cens.data.1 )

  # P2: 
  right.cens.data.2 <- KMRightCensor( my.data, chP2 )
  fitP2 <- LeftFit( right.cens.data.2, chP1 )

  # P3: 
  right.cens.data.3 <- KMRightCensor( my.data, chP3 )
  fitP3 <- LeftFit( right.cens.data.3, chP2 )

  # 4: 
  fitP4 <- LeftFit( my.data, chP3 )
  plot( fitP1, list( fitP2, fitP3, fitP4 ) )
@

Note, to plot the results you need to put all left-truncated models in a list. Each change-point will be marked with a dashed line (Figure~\ref{fig:npieces}). The simulation step also requires all models to be in a list.  The prediction figure is plotted as normal (Figure~\ref{fig:prednpieces})
<<prednpieces, fig.cap="Predictions using the model with three change-points.">>=
  lft.models <- list( fitP2, fitP3, fitP4 )
  results <- simulatePW( right.cens.fit, lft.models,  
    Nsim = 500, #Number of simulations to perform
    seed = 20160322 )
  results <- predict( results, event.pred=900 )
  plot( results, show.title=TRUE )
@


\section{Future work}
\label{sec:futwork}
No error estimates are provided for the estimation of the change-point. This can be achieved by non-parametric bootstrapping. This will help in interpreting how precise the estimate is and also whether an effect is present or not. We are also looking into a mixture model that may be fitted directly to the data including a lag-effect.


\bibliographystyle{plain}
\bibliography{eventTools}

\end{document}

